# ğŸ· Wine Model Interpretability Framework

A comprehensive machine learning interpretability framework for wine quality prediction, featuring enhanced feature engineering, SHAP explanations, LIME analysis, and rich visualizations.

![Wine Analysis](docs/interface.png)

## ğŸŒŸ Key Features

- **ğŸ” Advanced Interpretability**: SHAP and LIME explanations with meaningful feature names
- **ğŸ‡ Enhanced Feature Engineering**: Transform basic wine data into 21+ interpretable features
- **ğŸ“Š Rich Visualizations**: Interactive plots showing model behavior and feature importance
- **ğŸ¤– Multiple ML Models**: Compare LightGBM and XGBoost performance
- **ğŸ› ï¸ Complete Pipeline**: Automated preprocessing, training, and analysis
- **ğŸ“ˆ No Target Leakage**: Properly engineered features without data leakage

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd wine-interpretability

# Install dependencies
pip install -r requirements.txt

# Install the package in development mode
pip install -e .
```

### Run Analysis

```bash
# Open the main notebook
jupyter notebook examples/fixed_interpretability_workflow.ipynb

# Or run a quick analysis
python examples/sample_wine_analysis.py
```

## ğŸ“Š Enhanced Features

Transform basic wine data into rich, interpretable features:

| **Original (5 features)** | **Enhanced (21+ features)** |
|---------------------------|------------------------------|
| `ABV` | `ABV` + `abv_category` (Low/Medium/High/Very High) |
| `wine_type_encoded` | `Type` + `wine_type_encoded` (Red, White, Sparkling, etc.) |
| `body_encoded` | `Body` + `body_encoded` (Light, Medium, Full-bodied) |
| `acidity_encoded` | `Acidity` + `acidity_encoded` (Low, Medium, High) |
| `rating_count` | `rating_count` + popularity metrics |
| | **ğŸ†• Grape Varieties**: `primary_grape` (46 varieties) |
| | **ğŸ†• Geographic**: `Country` (17 countries), `RegionName` (77 regions) |
| | **ğŸ†• Food Pairings**: `primary_pairing` (16 pairing types) |
| | **ğŸ†• Wine Characteristics**: `is_blend`, `Elaborate` method |
| | **ğŸ†• Derived Features**: `grape_count`, `vintage_count`, `vintage_range` |

## ğŸ¯ Results Comparison

### Before Enhancement
```
LIME Feature Importance:
- 13.0: 0.045    # Cryptic number
- 1.0: 0.032     # Meaningless
- 4.0: 0.028     # Unclear
```

### After Enhancement
```
LIME Feature Importance:
- Chardonnay: 0.045      # Clear grape variety
- France: 0.032          # Interpretable country
- Beef pairing: 0.028    # Meaningful food pairing
- Bordeaux: 0.025        # Recognizable region
- Single varietal: 0.022 # Wine characteristic
```

## ï¿½ Peroject Structure

```
wine_interpretability/
â”œâ”€â”€ ğŸ· wine_interpretability/     # Core package
â”‚   â”œâ”€â”€ models/                   # ML model trainers
â”‚   â”‚   â”œâ”€â”€ lightgbm_trainer.py   # LightGBM implementation
â”‚   â”‚   â””â”€â”€ xgboost_trainer.py    # XGBoost implementation
â”‚   â”œâ”€â”€ explainers/               # Interpretability tools
â”‚   â”‚   â”œâ”€â”€ shap_explainer.py     # SHAP explanations
â”‚   â”‚   â”œâ”€â”€ lime_explainer.py     # LIME explanations
â”‚   â”‚   â””â”€â”€ comparison.py         # Compare explanations
â”‚   â”œâ”€â”€ visualizers/              # Plotting and visualization
â”‚   â”‚   â””â”€â”€ export.py             # Export visualizations
â”‚   â”œâ”€â”€ utils/                    # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ data_loader.py        # Data loading
â”‚   â”‚   â”œâ”€â”€ feature_processor.py  # Feature engineering
â”‚   â”‚   â””â”€â”€ data_exporter.py      # Export results
â”‚   â”œâ”€â”€ config.py                 # Configuration classes
â”‚   â””â”€â”€ main.py                   # Main application interface
â”œâ”€â”€ ğŸ““ examples/                  # Example notebooks and scripts
â”‚   â”œâ”€â”€ fixed_interpretability_workflow.ipynb  # Main notebook
â”‚   â”œâ”€â”€ global_explanation_example.py          # SHAP examples
â”‚   â”œâ”€â”€ local_explanation_example.py           # LIME examples
â”‚   â””â”€â”€ outputs/                  # Analysis results
â”œâ”€â”€ ğŸ› ï¸ utils/                     # Utility scripts
â”‚   â””â”€â”€ enhanced_data_loader.py   # Enhanced feature engineering
â”œâ”€â”€ ğŸ“Š data/                      # Processed datasets
â”‚   â”œâ”€â”€ enhanced_wine_analysis_data.csv  # 21-feature dataset
â”‚   â””â”€â”€ wine_analysis_data_fixed.csv     # Original clean dataset
â”œâ”€â”€ ğŸ“ Dataset/                   # Raw datasets
â”‚   â””â”€â”€ last/                     # XWines dataset files
â””â”€â”€ ğŸ“š docs/                      # Documentation and images
```

## ğŸ”¬ Analysis Workflow

### 1. Data Enhancement
```python
from utils.enhanced_data_loader import create_enhanced_wine_features_from_merged

# Transform 5 basic features into 21+ enhanced features
data = create_enhanced_wine_features_from_merged(
    data_path="data/wine_analysis_data_fixed.csv",
    standardize=True,
    imputation_strategy='median'
)
```

### 2. Model Training
```python
from wine_interpretability.main import WineInterpretabilityApp
from wine_interpretability.config import *

# Configure and train models
config = PipelineConfig(
    model_config=ModelConfig(model_type=ModelType.LIGHTGBM),
    explanation_config=ExplanationConfig(lime_num_features=10),
    visualization_config=VisualizationConfig(figure_size=(14, 10))
)

app = WineInterpretabilityApp(config)
results = app.run_complete_analysis('data/enhanced_wine_analysis_data.csv', 'quality')
```

### 3. Interpretability Analysis
- **SHAP Global**: Feature importance across all predictions
- **SHAP Local**: Individual prediction explanations
- **LIME**: Local interpretable explanations with feature names
- **Comparison**: Side-by-side SHAP vs LIME analysis

## ğŸ“ˆ Visualizations

The framework generates comprehensive visualizations:

- **ğŸ¯ SHAP Beeswarm Plots**: Global feature importance with value distributions
- **ğŸ“Š LIME Bar Charts**: Local explanations for individual predictions
- **ğŸŒŠ SHAP Waterfall**: Step-by-step prediction breakdown
- **ğŸ“ˆ Feature Importance**: Model-based feature rankings
- **ğŸ”„ Explanation Comparison**: SHAP vs LIME consistency analysis

## ğŸ› ï¸ Configuration Options

### Model Configuration
```python
ModelConfig(
    model_type=ModelType.LIGHTGBM,  # or XGBOOST
    optimization_trials=20,
    cross_validation_folds=5,
    hyperparameter_space={...}
)
```

### Explanation Configuration
```python
ExplanationConfig(
    shap_explainer_type=SHAPExplainerType.TREE,
    lime_num_features=10,           # Number of features to show
    lime_num_samples=2000,          # LIME sampling size
    background_samples=100          # SHAP background samples
)
```

### Visualization Configuration
```python
VisualizationConfig(
    figure_size=(14, 10),
    dpi=150,
    save_format="png",
    show_plots=True
)
```

## ğŸ“Š Dataset Information

### XWines Dataset
- **Source**: XWines wine recommendation dataset
- **Wines**: 100 wines with detailed characteristics
- **Ratings**: 1,000+ user ratings
- **Features**: Wine type, grape varieties, regions, food pairings, vintages

### Enhanced Features
- **Categorical**: 15+ features including grape varieties, countries, regions
- **Numerical**: 6+ features including ABV, counts, and derived metrics
- **No Target Leakage**: Properly excludes rating-derived features

## ğŸ¯ Use Cases

- **ğŸ· Wine Industry**: Understand quality drivers for wine production
- **ğŸ“Š Data Science**: Learn interpretable ML techniques
- **ğŸ“ Education**: Teach feature engineering and model interpretability
- **ğŸ”¬ Research**: Study explainable AI methods in practice

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **XWines Dataset**: Wine recommendation dataset
- **SHAP**: SHapley Additive exPlanations library
- **LIME**: Local Interpretable Model-agnostic Explanations
- **LightGBM & XGBoost**: Gradient boosting frameworks

## ğŸ“ Support

- ğŸ“§ **Issues**: [GitHub Issues](../../issues)
- ğŸ“š **Documentation**: See `docs/` directory
- ï¿½ **Discussions**: [GitHub Discussions](../../discussions)

---

**Transform your wine quality predictions from cryptic numbers to meaningful insights! ğŸ·âœ¨**